{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Building a Markov Chain </h2>\n",
    "<br>\n",
    "<p> Using the twitter history of Boys' Life Magazine, create the probabilistic foundation for a Markov Chain and then generate new (and hopefully entertaining) tweets in the voice of Boys' Life</p>\n",
    "<p>The timeline used is from Tue Apr 28, 2015 until Thursday Apr 13, 2017</p>\n",
    "<br>\n",
    "<sub>1. http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/ </sub><br>\n",
    "<sub>2. https://codereview.stackexchange.com/questions/24276/implementation-of-a-markov-chain</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python (3, 5, 2)\n",
      "twython v.3.4.0\n",
      "pandas v.0.19.2\n",
      "ujson v.1.35\n"
     ]
    }
   ],
   "source": [
    "#standard library\n",
    "import sys\n",
    "print(\"Python {}\".format(sys.version_info[:3]))\n",
    "import string\n",
    "import random\n",
    "\n",
    "#packages\n",
    "import twython\n",
    "from twython import Twython\n",
    "from twython import TwythonStreamer\n",
    "print(\"twython v.{}\".format(twython.__version__))\n",
    "import pandas as pd\n",
    "print(\"pandas v.{}\".format(pd.__version__))\n",
    "import ujson as json\n",
    "print('ujson v.{}'.format(json.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('D:\\\\Python\\\\twitter_credentials.json', 'r') as c:\n",
    "    credentials = json.load(c)\n",
    "\n",
    "CONSUMER_KEY = credentials['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = credentials['CONSUMER_SECRET']\n",
    "ACCESS_TOKEN = credentials['ACCESS_TOKEN']\n",
    "ACCESS_TOKEN_SECRET = credentials['ACCESS_TOKEN_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweets(twitter_id):\n",
    "    tweets = []\n",
    "    \n",
    "    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    result = twitter.get_user_timeline(screen_name = twitter_id,\n",
    "                                       include_rts = False,\n",
    "                                       count = 200)\n",
    "    last_id = result[-1]['id']\n",
    "    \n",
    "    tweets+=result\n",
    "    \n",
    "    continuation = True\n",
    "    while True:\n",
    "        result = twitter.get_user_timeline(screen_name = twitter_id, \n",
    "                                           include_rts = False, \n",
    "                                           count = 200, \n",
    "                                           max_id = last_id-1)\n",
    "        \n",
    "        if len(result)>0 and len(tweets)<10000:\n",
    "            tweets+=result\n",
    "            last_id = result[-1]['id']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bl_tweets = get_tweets('@BoysLife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_texts = []\n",
    "\n",
    "for tweet in bl_tweets:\n",
    "    tweet_texts.append(\"TWEETSTART \"+tweet['text'].replace(\"'\",\"\").replace('\"',\"\").replace('\\xa0',\" \").split('http')[0]+\" TWEETEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build Markov Chain Dictionary of words and those that follow them\n",
    "m_chain = {}\n",
    "\n",
    "for tweet in tweet_texts:\n",
    "    tweet_words = tweet.split()\n",
    "    for position, word in enumerate(tweet_words[:-1]):\n",
    "        if word in m_chain.keys():\n",
    "            m_chain[word].append(tweet_words[position+1])\n",
    "        else:\n",
    "            m_chain.update({word:[tweet_words[position+1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate new tweets...\n",
    "\n",
    "def get_new_tweet():\n",
    "    next_word = \"TWEETSTART\"\n",
    "    new_tweet = []\n",
    "\n",
    "    while True:\n",
    "        next_word = random.choice(m_chain[next_word])\n",
    "        if next_word == \"TWEETEND\":\n",
    "            break\n",
    "        new_tweet.append(next_word)\n",
    "    return(' '.join(new_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tweets = []\n",
    "for x in range(500):\n",
    "    new_tweets.append(get_new_tweet())\n",
    "    \n",
    "with open(\"D:\\\\BSA\\\\magazines_fun\\\\new_tweets3.txt\",\"w\") as f:\n",
    "    for tweet in new_tweets:\n",
    "        f.write(tweet+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>...And now the slightly more evil version: A Donald Trump Tweet markov chain...</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_tweets = get_tweets('@realDonaldTrump')\n",
    "\n",
    "tweet_texts = []\n",
    "\n",
    "for tweet in trump_tweets:\n",
    "    tweet_texts.append(\"TWEETSTART \"+tweet['text'].replace(\"'\",\"\").replace('\"',\"\").replace('\\xa0',\" \").split('http')[0]+\" TWEETEND\")\n",
    "    \n",
    "trump_chain = {}\n",
    "\n",
    "for tweet in tweet_texts:\n",
    "    tweet_words = tweet.split()\n",
    "    for position, word in enumerate(tweet_words[:-1]):\n",
    "        if word in trump_chain.keys():\n",
    "            trump_chain[word].append(tweet_words[position+1])\n",
    "        else:\n",
    "            trump_chain.update({word:[tweet_words[position+1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_trump_tweet():\n",
    "    next_word = \"TWEETSTART\"\n",
    "    new_tweet = []\n",
    "\n",
    "    while True:\n",
    "        next_word = random.choice(trump_chain[next_word])\n",
    "        if next_word == \"TWEETEND\":\n",
    "            break\n",
    "        new_tweet.append(next_word)\n",
    "    return(' '.join(new_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tweets = []\n",
    "for x in range(500):\n",
    "    new_tweets.append(new_trump_tweet())\n",
    "    \n",
    "with open(\"D:\\\\trump_tweets.txt\",\"w\") as f:\n",
    "    for tweet in new_tweets:\n",
    "        try: f.write(tweet+\"\\n\")\n",
    "        except: continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py352]",
   "language": "python",
   "name": "conda-env-py352-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
